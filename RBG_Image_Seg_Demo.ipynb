{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQejTH0hROT/iE/7IbUOpo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hlvEpZXno6MR"
      },
      "outputs": [],
      "source": [
        "# Install segmentation models package\n",
        "!pip install segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/parth1620/Human-Segmentation-Dataset-master.git"
      ],
      "metadata": {
        "id": "Q57RbclBo_Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "0dFPGywzpA63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path variables\n",
        "TRAIN_DATA_PATH = '/content/Human-Segmentation-Dataset-master/train.csv'\n",
        "DATA_DIR = '/content/'\n",
        "\n",
        "# Select the device to train on\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define hyperparameters\n",
        "EPOCHS = 10        # number of epochs\n",
        "LR = 0.001         # Learning rate\n",
        "IMG_SIZE = 320     # Size of image\n",
        "BATCH_SIZE = 32    # Batch size\n",
        "\n",
        "# Define pretrained encoder model and weights\n",
        "ENCODER = 'timm-efficientnet-b0'\n",
        "WEIGHTS = 'imagenet'"
      ],
      "metadata": {
        "id": "Yf1UZgQOpDxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "Lky10o9jpMcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(TRAIN_DATA_PATH)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Mtpv4iexpJ4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore the Data"
      ],
      "metadata": {
        "id": "BBxz7epNpR0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = df.iloc[np.random.randint(0, df.shape[0], size=5)]\n",
        "\n",
        "def generate_sample_images(sample):\n",
        "    imgs = sample.images\n",
        "\n",
        "    _, ax = plt.subplots(1, 5, figsize=(15,3))\n",
        "    ax = ax.flatten()\n",
        "\n",
        "    for i, image in enumerate(imgs):\n",
        "        image = cv2.imread(image)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        ax[i].set_title(\"IMAGE\")\n",
        "        ax[i].imshow(image)\n",
        "\n",
        "def generate_sample_masks(sample):\n",
        "    masks = sample.masks\n",
        "\n",
        "    _, ax = plt.subplots(1, 5, figsize=(15,3))\n",
        "    ax = ax.flatten()\n",
        "\n",
        "    for i, mask in enumerate(masks):\n",
        "        mask = cv2.imread(mask, cv2.IMREAD_GRAYSCALE) / 255.0\n",
        "\n",
        "        ax[i].set_title(\"GROUND TRUTH\")\n",
        "        ax[i].imshow(mask, cmap='gray')"
      ],
      "metadata": {
        "id": "8R6060uvpPBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sample_images(sample)\n",
        "generate_sample_masks(sample)"
      ],
      "metadata": {
        "id": "OhVgNhKHpUwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the Data"
      ],
      "metadata": {
        "id": "r_49iffZpW0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data in separate train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=57)"
      ],
      "metadata": {
        "id": "Edtu2M-kpWGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augnebtation"
      ],
      "metadata": {
        "id": "fhaJ4IMhpbz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image augmentation library\n",
        "import albumentations as A"
      ],
      "metadata": {
        "id": "Si8vN0pFpa7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the augmentations\n",
        "def get_train_augs():\n",
        "    return A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "        A.HorizontalFlip(p=0.5),      # Horizontal Flip with 0.5 probability\n",
        "        A.VerticalFlip(p=0.5)         # Vertical Flip with 0.5 probability\n",
        "    ], is_check_shapes=False)\n",
        "\n",
        "def get_val_augs():\n",
        "    return A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE)\n",
        "    ], is_check_shapes=False)"
      ],
      "metadata": {
        "id": "sGaBk6d0pZyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing the Dataset: (channels, Height, Width) format, /255 normalization"
      ],
      "metadata": {
        "id": "6yrl15GrpppS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "FbNGx4Cup02r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom dataset class\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, df, augs):\n",
        "        self.df = df\n",
        "        self.augs = augs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.df.iloc[idx]\n",
        "        image = sample.images\n",
        "        mask = sample.masks\n",
        "\n",
        "        # Read images and masks\n",
        "        image = cv2.imread(image)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(mask, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "\n",
        "        #print(f\"Shapes of images before augmentation: {image.shape}\")\n",
        "        #print(f\"Shapes of masks before augmentation: {mask.shape}\")\n",
        "\n",
        "        # Apply augmentations\n",
        "        if self.augs:\n",
        "            data = self.augs(image=image, mask=mask)\n",
        "            image = data['image']\n",
        "            mask = data['mask']\n",
        "\n",
        "        #print(f\"\\nShapes of images after augmentation: {image.shape}\")\n",
        "        #print(f\"Shapes of masks after augmentation: {mask.shape}\")\n",
        "\n",
        "        # Transpose image dimensions in pytorch format\n",
        "        # (H,W,C) -> (C,H,W)\n",
        "        image = np.transpose(image, (2,0,1)).astype(np.float32)\n",
        "        mask = np.transpose(mask, (2,0,1)).astype(np.float32)\n",
        "\n",
        "        # Normalize the images and masks\n",
        "        image = torch.Tensor(image) / 255.0\n",
        "        mask = torch.round(torch.Tensor(mask) / 255.0)\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "fGPKab0zp4zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Processed train and validation sets\n",
        "train_data = SegmentationDataset(train_df, get_train_augs())\n",
        "val_data = SegmentationDataset(val_df, get_val_augs())"
      ],
      "metadata": {
        "id": "wA9Fz9YZp-3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Size of Trainset : {len(train_data)}\")\n",
        "print(f\"Size of Validset : {len(val_data)}\")"
      ],
      "metadata": {
        "id": "F99WLB6NqA4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample image, mask pair:"
      ],
      "metadata": {
        "id": "1BthpbRMqEq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def processed_image(idx):\n",
        "    image, mask = train_data[idx]\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(np.transpose(image, (1,2,0)))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"IMAGE\");\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(np.transpose(mask, (1,2,0)), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(\"GROUND TRUTH\");\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xqdeVt5bqD2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in np.random.randint(0, len(train_data), 5):\n",
        "    processed_image(i)"
      ],
      "metadata": {
        "id": "c6b_em_MqIDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset into Batches"
      ],
      "metadata": {
        "id": "GlmD9ILGqSnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "P2etXllgqUad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "print(f\"Total number of batches in Train Loader: {len(trainloader)}\")\n",
        "print(f\"Total number of batches in Val Loader: {len(valloader)}\")"
      ],
      "metadata": {
        "id": "Tl9idbbAqWVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, mask in trainloader:\n",
        "    print(f\"Size of one batch of images: {image.shape}\")\n",
        "    print(f\"Size of one batch of masks: {mask.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "fBNWzgeBqZNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Segmentation Model: based on UNet++\n",
        "\n",
        "\n",
        "*   efficient net as the encoder model\n",
        "*   weights from imagenet\n",
        "*   3 RGB channels\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OFXqdrrgqcFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch.losses import DiceLoss"
      ],
      "metadata": {
        "id": "PELEVprkqvyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegmentationModel, self).__init__()\n",
        "\n",
        "        self.model = smp.UnetPlusPlus(\n",
        "            encoder_name=ENCODER,\n",
        "            encoder_weights=WEIGHTS,\n",
        "            in_channels=3,\n",
        "            classes=1,\n",
        "            activation=None)\n",
        "\n",
        "    def forward(self, images, masks=None):\n",
        "        logits = self.model(images)\n",
        "\n",
        "        if masks != None:\n",
        "            loss1 = DiceLoss(mode='binary')(logits, masks) # measure of dissimilarity between the predicted segmentation mask and the true segmentation\n",
        "            loss2 = nn.BCEWithLogitsLoss()(logits, masks)\n",
        "            return logits, loss1 + loss2\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "uwNHys8uq0nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SegmentationModel()\n",
        "model.to(DEVICE);"
      ],
      "metadata": {
        "id": "DBb5aet3rG1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Train and Validation Function"
      ],
      "metadata": {
        "id": "6Xq5W0WfrJW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the model\n",
        "def train_model(data_loader, model, optimizer):\n",
        "    total_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for images, masks in tqdm(data_loader):\n",
        "        images = images.to(DEVICE)\n",
        "        masks = masks.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, loss = model(images, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "EUAHOHdgrMpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate the model\n",
        "def eval_model(data_loader, model):\n",
        "    total_loss = 0.0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(data_loader):\n",
        "            images = images.to(DEVICE)\n",
        "            masks = masks.to(DEVICE)\n",
        "\n",
        "            logits, loss = model(images, masks)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        return total_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "QAr81d3grRAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training"
      ],
      "metadata": {
        "id": "PARheghnrTve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "F0TO1Dx3rTFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation loop\n",
        "best_val_loss = 1e9\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    train_loss = train_model(trainloader, model, optimizer)\n",
        "    val_loss = eval_model(valloader, model)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        # Save the best model\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "        print(\"MODEL SAVED\")\n",
        "\n",
        "        best_val_loss = val_loss\n",
        "\n",
        "    print(f\"\\033[1m\\033[92m Epoch {i+1} Train Loss {train_loss} Val Loss {val_loss}\")"
      ],
      "metadata": {
        "id": "S8HTZvGxrtau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "f-UO0U36ruEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "\n",
        "# Function to output the prediction mask\n",
        "def make_inference(idx):\n",
        "    image, mask = val_data[idx]\n",
        "    logits_mask = model(image.to(DEVICE).unsqueeze(0)) # (C, H, W) -> (1, C, H, W)\n",
        "\n",
        "    # Predicted mask\n",
        "    pred_mask = torch.sigmoid(logits_mask)\n",
        "    pred_mask = (pred_mask > 0.5) * 1.0\n",
        "\n",
        "    return image, mask, pred_mask"
      ],
      "metadata": {
        "id": "IJ96RZCYrvNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare predictions with original\n",
        "for i in np.random.randint(0, len(val_data), 5):\n",
        "    image, mask, pred_mask = make_inference(i)\n",
        "\n",
        "    # Show image\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(np.transpose(image, (1,2,0)))\n",
        "    plt.axis('off')\n",
        "    plt.title('IMAGE');\n",
        "\n",
        "    # Show original mask\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(np.transpose(mask, (1,2,0)), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('GROUND TRUTH');\n",
        "\n",
        "    # Show predicted mask\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(np.transpose(pred_mask.detach().cpu().squeeze(0), (1,2,0)), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('PREDICTION');"
      ],
      "metadata": {
        "id": "7E4fAp8ErznC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}